{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from string import punctuation\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm probably just going to use the words in descriptions. Let's see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "with open(\"20171107_AstroKomrade_followers.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    \n",
    "    for line in infile.readlines() :\n",
    "        line = line.strip(\"\\n\").split(\"\\t\") # need to specify what we're stripping here.\n",
    "        \n",
    "        if line[6] : # test for empty description\n",
    "            d.append((line[6],'astronaut'))\n",
    "\n",
    "with open(\"20171107_FlatEarthOrg_followers.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    \n",
    "    for line in infile.readlines() :\n",
    "        line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        if line[6] :\n",
    "            d.append((line[6],'flatearth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, let's look at a little of the data. I'll shuffle it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('instagram >>     ___criss_____', 'astronaut'), ('Native of the District. Uppsala University and Clemson University alumnus. Go Tigers!', 'astronaut'), ('Alhamdualliuh', 'astronaut')]\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(d)\n",
    "sample = d[:3]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to write a function that cleans up the description and maps it on to words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def desc_features(the_description) :\n",
    "    \"\"\" Input: A twitter description\n",
    "        Output: A dictionary listin the words that are in \n",
    "                the description.\n",
    "                \n",
    "        This function does some cleaning on the descriptions,\n",
    "        removing some punctuation, splitting on whitespace, \n",
    "        dropping to lower case. It returns a dictionary \n",
    "        of the form \n",
    "            {example : True,\n",
    "             word :    True}\n",
    "    \n",
    "        \"\"\"\n",
    "    exclude = set(punctuation)\n",
    "    \n",
    "    # Found this at https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\n",
    "    the_description = ''.join([ch.lower() for ch in the_description if ch not in exclude])\n",
    "    \n",
    "    word_list = the_description.split()\n",
    "\n",
    "    ret_val = {}\n",
    "    \n",
    "    for word in word_list :\n",
    "        ret_val[word] = True\n",
    "    \n",
    "    return(ret_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, it's a good idea to test your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with: instagram >>     ___criss_____\n",
      "-------------------Then got---------------------------\n",
      "{'criss': True, 'instagram': True}\n",
      "------------------------------------------------------\n",
      "Started with: Native of the District. Uppsala University and Clemson University alumnus. Go Tigers!\n",
      "-------------------Then got---------------------------\n",
      "{'alumnus': True,\n",
      " 'and': True,\n",
      " 'clemson': True,\n",
      " 'district': True,\n",
      " 'go': True,\n",
      " 'native': True,\n",
      " 'of': True,\n",
      " 'the': True,\n",
      " 'tigers': True,\n",
      " 'university': True,\n",
      " 'uppsala': True}\n",
      "------------------------------------------------------\n",
      "Started with: Alhamdualliuh\n",
      "-------------------Then got---------------------------\n",
      "{'alhamdualliuh': True}\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for a in sample :\n",
    "    desc, label = a\n",
    "    print(\"Started with: \" + desc)\n",
    "    print(\"-------------------Then got---------------------------\")\n",
    "    pprint(desc_features(desc))\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're ready to do the NB stuff. It's actually shockingly easy at this point, since we've done the work to set it up. We've got 60K total descriptions (found by typing `len(d)` in a cell). That's big enough that I'll use a full 5000 for our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_size = 5000\n",
    "\n",
    "featuresets = [(desc_features(desc), label) for (desc, label) in d]\n",
    "train_set, test_set = featuresets[test_set_size:], featuresets[:test_set_size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not terrible, assuming it's about a 50/50 split. Let's see what that is, using my trick from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'astronaut': 39744, 'flatearth': 20564})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([label for desc, label in d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, Astronaut is about 66% of the data, so we're not doing that much better than if we just guessed \"astronaut\" all the time. Well, we can think about making it better in a minute. For now, let's see what's predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               flatearth = True           flatea : astron =    227.7 : 1.0\n",
      "                    flat = True           flatea : astron =    110.6 : 1.0\n",
      "                    mgwv = True           flatea : astron =     70.3 : 1.0\n",
      "                    rico = True           astron : flatea =     40.1 : 1.0\n",
      "                 truther = True           flatea : astron =     36.8 : 1.0\n",
      "             flatearther = True           flatea : astron =     36.8 : 1.0\n",
      "                     iss = True           astron : flatea =     32.6 : 1.0\n",
      "                 earther = True           flatea : astron =     31.8 : 1.0\n",
      "           follow4follow = True           flatea : astron =     31.6 : 1.0\n",
      "               astronaut = True           astron : flatea =     28.5 : 1.0\n",
      "                    kita = True           flatea : astron =     27.7 : 1.0\n",
      "             exploration = True           astron : flatea =     27.6 : 1.0\n",
      "          teamfollowback = True           flatea : astron =     26.0 : 1.0\n",
      "                  puerto = True           astron : flatea =     26.0 : 1.0\n",
      "                     f4f = True           flatea : astron =     25.7 : 1.0\n",
      "                     nwo = True           flatea : astron =     25.2 : 1.0\n",
      "                exposing = True           flatea : astron =     25.2 : 1.0\n",
      "              followback = True           flatea : astron =     23.8 : 1.0\n",
      "                followme = True           flatea : astron =     22.6 : 1.0\n",
      "                      yg = True           flatea : astron =     21.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number 2 for me is [mgwv](https://www.drewtolbert.com/what-does-mgwv-mean/), which seems like a spammy thing. The flat earth group has a lot of spammy words (\"f4f\", \"teamfollowback\" in their most informative features, but also just a lot of words like \"flat\". Not the most impressive model ever.\n",
    "\n",
    "If I was going to try to improve it, here's some stuff I'd try:\n",
    "\n",
    "1. Remove stopwords: We haven't talked about them much, but those are just our most common words. Might not matter, but it'd be cleaner. \n",
    "1. Limit the model to just the top $N$ remaining words. Not sure what to pick for $N$, but I'd try 1000 or so. It'd be worth it to do the whole `train_set/dev_test_set/test_set` if we were headed down this path and we could try a bunch of $N$s. \n",
    "1. See if number of followers is predictive. Using continuous variables in Naive Bayes is [a bit tricky](https://stats.stackexchange.com/questions/61034/naive-bayes-on-continuous-variables), but it can sometimes be quite predictive. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
